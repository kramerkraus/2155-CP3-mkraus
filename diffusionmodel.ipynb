{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvrpphChnvX915zdORqytA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kramerkraus/2155-CP3-mkraus/blob/main/diffusionmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o2pQC4yDwN6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "110788b8",
        "outputId": "e9df4a86-15e5-4aac-bbea-acb98203fc72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset splits from: /content/2155-CP3-mkraus/dataset\n",
            "\n",
            "Loading train split...\n",
            "  ✓ train_original.csv: (2998, 37)\n",
            "  ✓ train_imputed.csv: (2998, 37)\n",
            "  ✓ train_missing_mask.csv: (2998, 37)\n",
            "\n",
            "Loading val split...\n",
            "  ✓ val_original.csv: (375, 37)\n",
            "  ✓ val_imputed.csv: (375, 37)\n",
            "  ✓ val_missing_mask.csv: (375, 37)\n",
            "\n",
            "Loading test split...\n",
            "  ✓ test_original.csv: (375, 37)\n",
            "  ✓ test_imputed.csv: (375, 37)\n",
            "  ✓ test_missing_mask.csv: (375, 37)\n",
            "\n",
            "Loading test2 split...\n",
            "  ✓ test2_imputed.csv: (417, 37)\n",
            "  ✓ test2_missing_mask.csv: (417, 37)\n",
            "\n",
            "✓ Features loaded: 37 features\n",
            "Feature names: ['Feature 1', 'Feature 2', 'Feature 3', 'Feature 4', 'Feature 5']...['Feature 33', 'Feature 34', 'Feature 35', 'Feature 36', 'Feature 37']\n"
          ]
        }
      ],
      "source": [
        "# Load dataset from CSV files\n",
        "data_dir = '/content/2155-CP3-mkraus/dataset'\n",
        "splits = load_dataset_splits(data_dir)\n",
        "\n",
        "# Get feature names from the CSV file\n",
        "feature_names = pd.read_csv(os.path.join(data_dir, 'train_original.csv')).columns.tolist()\n",
        "print(f\"\\n✓ Features loaded: {len(feature_names)} features\")\n",
        "print(f\"Feature names: {feature_names[:5]}...{feature_names[-5:]}\")  # Show first and last 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bfce965",
        "outputId": "a64fdc5e-fb2d-4c16-9de7-715f30622237"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "DATASET ANALYSIS\n",
            "======================================================================\n",
            "\n",
            "Data shapes:\n",
            "  - Training: (2998, 37)\n",
            "  - Validation: (375, 37)\n",
            "  - Test: (375, 37)\n",
            "  - Test2: (417, 37) (evaluation set - no ground truth)\n"
          ]
        }
      ],
      "source": [
        "# Data exploration and analysis\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DATASET ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Extract data for easier access\n",
        "X_train = splits['train']['imputed']\n",
        "mask_train = splits['train']['missing_mask']\n",
        "X_train_original = splits['train']['original']\n",
        "\n",
        "X_val = splits['val']['imputed']\n",
        "mask_val = splits['val']['missing_mask']\n",
        "X_val_original = splits['val']['original']\n",
        "\n",
        "X_test = splits['test']['imputed']\n",
        "mask_test = splits['test']['missing_mask']\n",
        "X_test_original = splits['test']['original']\n",
        "\n",
        "# Test2 data (no original available for evaluation)\n",
        "X_test2 = splits['test2']['imputed']\n",
        "mask_test2 = splits['test2']['missing_mask']\n",
        "\n",
        "print(f\"\\nData shapes:\")\n",
        "print(f\"  - Training: {X_train.shape}\")\n",
        "print(f\"  - Validation: {X_val.shape}\")\n",
        "print(f\"  - Test: {X_test.shape}\")\n",
        "print(f\"  - Test2: {X_test2.shape} (evaluation set - no ground truth)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87af0cf5",
        "outputId": "adfbb6f9-c29a-4241-99b8-9ca5daed2e06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "DATA PREPROCESSING\n",
            "======================================================================\n",
            "Processing missing values and preparing data...\n",
            "Mask convention: True=missing, False=observed (in original masks)\n",
            "\n",
            "✓ Data preprocessing completed successfully\n",
            "  - Training data range: [0.000, 1.000]\n",
            "  - Validation data range: [0.000, 1.000]\n",
            "  - Test data range: [0.000, 1.000]\n",
            "\n",
            "Creating data loaders with batch size: 64\n",
            "\n",
            "Sample batch shape: torch.Size([64, 37])\n",
            "Sample batch mask shape: torch.Size([64, 37])\n",
            "Sample batch missing percentage: 20.3%\n"
          ]
        }
      ],
      "source": [
        "# Data Preprocessing (Handle Missing Values)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DATA PREPROCESSING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Handle missing values properly\n",
        "print(\"Processing missing values and preparing data...\")\n",
        "print(\"Mask convention: True=missing, False=observed (in original masks)\")\n",
        "\n",
        "print(f\"\\n✓ Data preprocessing completed successfully\")\n",
        "print(f\"  - Training data range: [{X_train_original[~mask_train].min():.3f}, {X_train_original[~mask_train].max():.3f}]\")\n",
        "print(f\"  - Validation data range: [{X_val_original[~mask_val].min():.3f}, {X_val_original[~mask_val].max():.3f}]\")\n",
        "print(f\"  - Test data range: [{X_test_original[~mask_test].min():.3f}, {X_test_original[~mask_test].max():.3f}]\")\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 64\n",
        "print(f\"\\nCreating data loaders with batch size: {batch_size}\")\n",
        "\n",
        "train_dataset = TensorDataset(torch.FloatTensor(X_train_original), torch.FloatTensor((~mask_train).astype(float)))\n",
        "val_dataset = TensorDataset(torch.FloatTensor(X_val_original), torch.FloatTensor((~mask_val).astype(float)))\n",
        "test_dataset = TensorDataset(torch.FloatTensor(X_test_original), torch.FloatTensor((~mask_test).astype(float)))\n",
        "test2_dataset = TensorDataset(torch.FloatTensor(X_test2), torch.FloatTensor((~mask_test2).astype(float)))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "test2_loader = DataLoader(test2_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Preview a batch\n",
        "sample_batch_data, sample_batch_mask = next(iter(train_loader))\n",
        "print(f\"\\nSample batch shape: {sample_batch_data.shape}\")\n",
        "print(f\"Sample batch mask shape: {sample_batch_mask.shape}\")\n",
        "print(f\"Sample batch missing percentage: {(sample_batch_mask == 0).float().mean().item()*100:.1f}%\")  # 0 = missing in model tensors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bMjXOpysu0la"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1. Small MLP backbone (denoiser)\n",
        "# --------------------------------------------------\n",
        "\n",
        "class MLPDenoiser(nn.Module):\n",
        "    def __init__(self, input_dim=37, hidden=256):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim + 1 + input_dim, hidden), # x + t + mask\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, input_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x_t, t, mask):\n",
        "        \"\"\"\n",
        "        x_t: noised data\n",
        "        t: time step (batch, 1)\n",
        "        mask: binary mask (1 = observed, 0 = missing)\n",
        "        \"\"\"\n",
        "        t = t / 1000.0       # normalize time\n",
        "        inp = torch.cat([x_t, t, mask], dim=1)\n",
        "        return self.net(inp)\n",
        "\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 2. Diffusion core (betas, schedules, noise)\n",
        "# --------------------------------------------------\n",
        "\n",
        "def make_beta_schedule(T=1000, start=1e-4, end=0.02):\n",
        "    return torch.linspace(start, end, T)\n",
        "\n",
        "\n",
        "class Diffusion(nn.Module):\n",
        "    def __init__(self, input_dim, timesteps=1000):\n",
        "        super().__init__()\n",
        "        self.T = timesteps\n",
        "        betas = make_beta_schedule(timesteps)\n",
        "        alphas = 1.0 - betas\n",
        "        alphas_cum = torch.cumprod(alphas, dim=0)\n",
        "\n",
        "        self.register_buffer(\"betas\", betas)\n",
        "        self.register_buffer(\"alphas\", alphas)\n",
        "        self.register_buffer(\"alphas_cum\", alphas_cum)\n",
        "\n",
        "        self.model = MLPDenoiser(input_dim=input_dim)\n",
        "\n",
        "    # -------------------------\n",
        "    # q(x_t | x_0)\n",
        "    # -------------------------\n",
        "    def q_sample(self, x0, t, noise=None):\n",
        "        if noise is None:\n",
        "            noise = torch.randn_like(x0)\n",
        "        a_bar = self.alphas_cum[t].unsqueeze(1)\n",
        "        return torch.sqrt(a_bar) * x0 + torch.sqrt(1 - a_bar) * noise, noise\n",
        "\n",
        "    # -------------------------\n",
        "    # Training step\n",
        "    # -------------------------\n",
        "    def forward(self, x0, mask):\n",
        "        \"\"\"\n",
        "        x0 : clean data (batch, D)\n",
        "        mask : 1 = observed, 0 = missing\n",
        "        \"\"\"\n",
        "        B = x0.shape[0]\n",
        "        device = x0.device\n",
        "\n",
        "        # Random time t for each sample\n",
        "        t = torch.randint(0, self.T, (B,), device=device)\n",
        "\n",
        "        # Noise forward\n",
        "        xt, noise = self.q_sample(x0, t, noise=None)\n",
        "\n",
        "        # Condition on observed values\n",
        "        xt = xt * (1 - mask) + x0 * mask\n",
        "\n",
        "        # Predict noise\n",
        "        noise_pred = self.model(xt, t.unsqueeze(1).float(), mask)\n",
        "\n",
        "        # Loss only on missing entries\n",
        "        loss = ((noise_pred - noise) ** 2 * (1 - mask)).mean()\n",
        "        return loss\n",
        "\n",
        "    # -------------------------\n",
        "    # Sampling / imputation\n",
        "    # -------------------------\n",
        "    @torch.no_grad()\n",
        "    def sample(self, x_obs, mask):\n",
        "        \"\"\"x_obs has missing entries set to anything (will overwrite them).\"\"\"\n",
        "        x = torch.randn_like(x_obs)\n",
        "\n",
        "        for t in reversed(range(self.T)):\n",
        "            bt = self.betas[t]\n",
        "            at = self.alphas[t]\n",
        "            a_bar = self.alphas_cum[t]\n",
        "\n",
        "            # Conditioner: always respect observed values\n",
        "            x = x * (1 - mask) + x_obs * mask\n",
        "\n",
        "            noise_pred = self.model(x, torch.tensor([[t]], device=x.device), mask)\n",
        "\n",
        "            # DDPM update step\n",
        "            coef1 = 1 / torch.sqrt(at)\n",
        "            coef2 = (1 - at) / torch.sqrt(1 - a_bar)\n",
        "\n",
        "            x = coef1 * (x - coef2 * noise_pred)\n",
        "\n",
        "            if t > 0:\n",
        "                x += torch.sqrt(bt) * torch.randn_like(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Diffusion(input_dim=37, timesteps=500).to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "u8bw1CxnvuMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(200):\n",
        "    for batch, mask in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        mask = mask.to(device)\n",
        "\n",
        "        loss = model(batch, mask)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    print(f\"epoch {epoch} | loss {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "T9GDCTjhvzcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_incomplete = X_test_imputed[i]      # has -1 replaced by something\n",
        "mask = (X_test_missing_mask[i] == 0)  # convert your mask to 1/0 observed/missing\n",
        "\n",
        "x_incomplete = torch.tensor(x_incomplete).float().to(device)\n",
        "mask = torch.tensor(mask).float().to(device)\n",
        "\n",
        "samples = []\n",
        "\n",
        "for _ in range(20):\n",
        "    x_gen = model.sample(x_incomplete.unsqueeze(0), mask.unsqueeze(0))\n",
        "    samples.append(x_gen.cpu().numpy())\n",
        "\n",
        "samples = np.array(samples)   # (20, 1, 37)"
      ],
      "metadata": {
        "id": "qXLJC4lUv3E8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
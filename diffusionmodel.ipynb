{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOBc/jAHtoRBGQ0VFV9Fckf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kramerkraus/2155-CP3-mkraus/blob/main/diffusionmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8c4efb4"
      },
      "source": [
        "%reset -f"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#free up all ram\n",
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "MN9gMyjxJS_O",
        "outputId": "4791d197-c8b2-4511-b034-04596f2ab156",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4346"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6622e9dd"
      },
      "outputs": [],
      "source": [
        "#make it so i can access files in the folder 2155-CP3-mkraus\n",
        "import sys\n",
        "sys.path.append('/content/2155-CP3-mkraus/')\n",
        "from utils import *\n",
        "from evaluate import *\n",
        "import random\n",
        "\n",
        "# Check if CUDA is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "110788b8"
      },
      "outputs": [],
      "source": [
        "# Load dataset from CSV files\n",
        "data_dir = '/content/2155-CP3-mkraus/dataset'\n",
        "splits = load_dataset_splits(data_dir)\n",
        "\n",
        "# Get feature names from the CSV file\n",
        "feature_names = pd.read_csv(os.path.join(data_dir, 'train_original.csv')).columns.tolist()\n",
        "print(f\"\\n✓ Features loaded: {len(feature_names)} features\")\n",
        "print(f\"Feature names: {feature_names[:5]}...{feature_names[-5:]}\")  # Show first and last 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bfce965"
      },
      "outputs": [],
      "source": [
        "# Data exploration and analysis\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DATASET ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Extract data for easier access\n",
        "X_train = splits['train']['imputed']\n",
        "mask_train = splits['train']['missing_mask']\n",
        "X_train_original = splits['train']['original']\n",
        "\n",
        "\n",
        "# for i in [18,14, 5]:\n",
        "#   print(i)\n",
        "#   X_traincpy = X_train.copy()\n",
        "\n",
        "#   #pick a random number between 0 and 36\n",
        "#   # k = random.randint(0,36)\n",
        "\n",
        "#   X_traincpy[:,i] = -1\n",
        "#   #append X_traincpy to the bottom of X_train\n",
        "#   X_train = np.vstack((X_train, X_traincpy))\n",
        "\n",
        "#   mask_traincpy = mask_train.copy()\n",
        "#   mask_traincpy[:,i] = 1\n",
        "\n",
        "#   #append mask_traincpy to the bottom of mask_train\n",
        "#   mask_train = np.vstack((mask_train, mask_traincpy))\n",
        "\n",
        "#   #append a copy of X_train_original to the bottom of itself\n",
        "#   X_train_original = np.vstack((X_train_original, X_train_original))\n",
        "\n",
        "for i in range(37):\n",
        "  print(i)\n",
        "  X_traincpy = X_train.copy()\n",
        "  X_traincpy = X_traincpy[0:300,:]\n",
        "\n",
        "  #pick a random number between 0 and 36\n",
        "  # k = random.randint(0,36)\n",
        "\n",
        "  X_traincpy[:,i] = -1\n",
        "  #append X_traincpy to the bottom of X_train\n",
        "  X_train = np.vstack((X_train, X_traincpy))\n",
        "\n",
        "  mask_traincpy = mask_train.copy()\n",
        "  mask_traincpy = mask_traincpy[0:300,:]\n",
        "  mask_traincpy[:,i] = 1\n",
        "\n",
        "  #append mask_traincpy to the bottom of mask_train\n",
        "  mask_train = np.vstack((mask_train, mask_traincpy))\n",
        "\n",
        "  #append a copy of X_train_original to the bottom of itself\n",
        "  X_train_original = np.vstack((X_train_original, X_train_original[0:300,:]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X_val = splits['val']['imputed']\n",
        "mask_val = splits['val']['missing_mask']\n",
        "X_val_original = splits['val']['original']\n",
        "\n",
        "X_test = splits['test']['imputed']\n",
        "mask_test = splits['test']['missing_mask']\n",
        "X_test_original = splits['test']['original']\n",
        "\n",
        "# Test2 data (no original available for evaluation)\n",
        "X_test2 = splits['test2']['imputed']\n",
        "mask_test2 = splits['test2']['missing_mask']\n",
        "\n",
        "print(f\"\\nData shapes:\")\n",
        "print(f\"  - Training: {X_train.shape}\")\n",
        "print(f\"  - Validation: {X_val.shape}\")\n",
        "print(f\"  - Test: {X_test.shape}\")\n",
        "print(f\"  - Test2: {X_test2.shape} (evaluation set - no ground truth)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87af0cf5"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing (Handle Missing Values)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DATA PREPROCESSING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Handle missing values properly\n",
        "print(\"Processing missing values and preparing data...\")\n",
        "print(\"Mask convention: True=missing, False=observed (in original masks)\")\n",
        "\n",
        "print(f\"\\n✓ Data preprocessing completed successfully\")\n",
        "print(f\"  - Training data range: [{X_train_original[~mask_train].min():.3f}, {X_train_original[~mask_train].max():.3f}]\")\n",
        "print(f\"  - Validation data range: [{X_val_original[~mask_val].min():.3f}, {X_val_original[~mask_val].max():.3f}]\")\n",
        "print(f\"  - Test data range: [{X_test_original[~mask_test].min():.3f}, {X_test_original[~mask_test].max():.3f}]\")\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 64\n",
        "print(f\"\\nCreating data loaders with batch size: {batch_size}\")\n",
        "\n",
        "train_dataset = TensorDataset(torch.FloatTensor(X_train_original), torch.FloatTensor((~mask_train).astype(float)))\n",
        "val_dataset = TensorDataset(torch.FloatTensor(X_val_original), torch.FloatTensor((~mask_val).astype(float)))\n",
        "test_dataset = TensorDataset(torch.FloatTensor(X_test_original), torch.FloatTensor((~mask_test).astype(float)))\n",
        "test2_dataset = TensorDataset(torch.FloatTensor(X_test2), torch.FloatTensor((~mask_test2).astype(float)))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "test2_loader = DataLoader(test2_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Preview a batch\n",
        "sample_batch_data, sample_batch_mask = next(iter(train_loader))\n",
        "print(f\"\\nSample batch shape: {sample_batch_data.shape}\")\n",
        "print(f\"Sample batch mask shape: {sample_batch_mask.shape}\")\n",
        "print(f\"Sample batch missing percentage: {(sample_batch_mask == 0).float().mean().item()*100:.1f}%\")  # 0 = missing in model tensors\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDenoiser(nn.Module):\n",
        "    def __init__(self, input_dim=37, d_model=4096, n_heads=64, depth=24):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # Project the raw vector into a transformer-hidden dimension\n",
        "        self.input_proj = nn.Linear(input_dim, d_model)\n",
        "\n",
        "        # Mask embedding (tells transformer which elements were observed)\n",
        "        self.mask_emb = nn.Linear(input_dim, d_model)\n",
        "\n",
        "        # Time embedding\n",
        "        self.time_emb = nn.Sequential(\n",
        "            nn.Linear(1, d_model),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(d_model, d_model),\n",
        "        )\n",
        "\n",
        "        # Transformer encoder layers\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=n_heads,\n",
        "            dim_feedforward=4*d_model,\n",
        "            batch_first=True,\n",
        "            activation=\"gelu\"\n",
        "        )\n",
        "\n",
        "        self.transformer = nn.TransformerEncoder(\n",
        "            encoder_layer,\n",
        "            num_layers=depth\n",
        "        )\n",
        "\n",
        "        # Project back to noise dimension\n",
        "        self.out_proj = nn.Linear(d_model, input_dim)\n",
        "\n",
        "    def forward(self, x_t, t, mask):\n",
        "        \"\"\"\n",
        "        x_t:  [B, D]\n",
        "        t:    [B, 1]\n",
        "        mask: [B, D]\n",
        "        \"\"\"\n",
        "        B, D = x_t.shape\n",
        "\n",
        "        # project inputs\n",
        "        h = self.input_proj(x_t)                    # [B, d]\n",
        "        m = self.mask_emb(mask)                    # [B, d]\n",
        "        te = self.time_emb(t)                      # [B, d]\n",
        "\n",
        "        h = h + m + te                              # fuse conditioning\n",
        "\n",
        "        # Transformer expects sequence; treat entire vector as 1 token\n",
        "        h = h.unsqueeze(1)                          # [B, 1, d]\n",
        "\n",
        "        h = self.transformer(h)                     # [B, 1, d]\n",
        "\n",
        "        out = self.out_proj(h.squeeze(1))           # [B, D]\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "ehCZSckuF5Si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMjXOpysu0la"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1. Small MLP backbone (denoiser)\n",
        "# --------------------------------------------------\n",
        "\n",
        "class MLPDenoiser(nn.Module):\n",
        "    def __init__(self, input_dim=37, hidden=256):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim + 1 + input_dim, hidden), # x + t + mask\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, input_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x_t, t, mask):\n",
        "        \"\"\"\n",
        "        x_t: noised data\n",
        "        t: time step (batch, 1)\n",
        "        mask: binary mask (1 = observed, 0 = missing)\n",
        "        \"\"\"\n",
        "        t = t / 1000.0       # normalize time\n",
        "        inp = torch.cat([x_t, t, mask], dim=1)\n",
        "        return self.net(inp)\n",
        "\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 2. Diffusion core (betas, schedules, noise)\n",
        "# --------------------------------------------------\n",
        "\n",
        "def make_beta_schedule(T=1000, start=1e-4, end=0.03):\n",
        "    return torch.linspace(start, end, T)\n",
        "\n",
        "\n",
        "class Diffusion(nn.Module):\n",
        "    def __init__(self, input_dim, timesteps=1000):\n",
        "        super().__init__()\n",
        "        self.T = timesteps\n",
        "        betas = make_beta_schedule(timesteps)\n",
        "        alphas = 1.0 - betas\n",
        "        alphas_cum = torch.cumprod(alphas, dim=0)\n",
        "\n",
        "        self.register_buffer(\"betas\", betas)\n",
        "        self.register_buffer(\"alphas\", alphas)\n",
        "        self.register_buffer(\"alphas_cum\", alphas_cum)\n",
        "\n",
        "        #self.model = MLPDenoiser(input_dim=input_dim)\n",
        "        self.model = TransformerDenoiser(input_dim=input_dim)\n",
        "\n",
        "    # -------------------------\n",
        "    # q(x_t | x_0)\n",
        "    # -------------------------\n",
        "    def q_sample(self, x0, t, noise=None):\n",
        "        if noise is None:\n",
        "            noise = torch.randn_like(x0)\n",
        "        a_bar = self.alphas_cum[t].unsqueeze(1)\n",
        "        return torch.sqrt(a_bar) * x0 + torch.sqrt(1 - a_bar) * noise, noise\n",
        "\n",
        "    # -------------------------\n",
        "    # Training step\n",
        "    # -------------------------\n",
        "    def forward(self, x0, mask):\n",
        "        \"\"\"\n",
        "        x0 : clean data (batch, D)\n",
        "        mask : 1 = observed, 0 = missing\n",
        "        \"\"\"\n",
        "        B = x0.shape[0]\n",
        "        device = x0.device\n",
        "\n",
        "        # Random time t for each sample\n",
        "        t = torch.randint(0, self.T, (B,), device=device)\n",
        "\n",
        "        # Noise forward\n",
        "        xt, noise = self.q_sample(x0, t, noise=None)\n",
        "\n",
        "        # Condition on observed values\n",
        "        xt = xt * (1 - mask) + x0 * mask\n",
        "\n",
        "        # Predict noise\n",
        "        noise_pred = self.model(xt, t.unsqueeze(1).float(), mask)\n",
        "\n",
        "        # Loss only on missing entries\n",
        "        loss = ((noise_pred - noise) ** 2 * (1 - mask)).mean()\n",
        "        return loss\n",
        "\n",
        "    # -------------------------\n",
        "    # Sampling / imputation\n",
        "    # -------------------------\n",
        "    @torch.no_grad()\n",
        "    def sample(self, x_obs, mask, guidance_scale=2.0):\n",
        "      \"\"\"x_obs has missing entries set to anything (will overwrite them).\n",
        "      guidance_scale: w in cfg (>=1). w=1.0 -> no guidance, w>1.0 -> stronger conditioning.\n",
        "      \"\"\"\n",
        "\n",
        "      x = torch.randn_like(x_obs)\n",
        "\n",
        "      # Define the target categories for Feature 26\n",
        "      feature_26_idx = 25 # Assuming 'Feature 26' is at index 25 (0-indexed)\n",
        "      allowed_categories = torch.tensor([0.0, 0.5, 1.0], device=x.device, dtype=torch.float32)\n",
        "\n",
        "      feature_25_idx = 24\n",
        "\n",
        "      for t in reversed(range(self.T)):\n",
        "          bt = self.betas[t]\n",
        "          at = self.alphas[t]\n",
        "          a_bar = self.alphas_cum[t]\n",
        "\n",
        "          # ----- prepare two inputs: uncond and cond -----\n",
        "          # For conditioned input, always respect observed values\n",
        "          x_cond = x * (1 - mask) + x_obs * mask\n",
        "\n",
        "          # For unconditioned input, do not inject observed values (i.e., no overwrite)\n",
        "          x_uncond = x  # same x but without overwritten observed entries\n",
        "\n",
        "          # t tensor\n",
        "          t_tensor = torch.full((x.shape[0], 1), t, device=x.device).float()\n",
        "\n",
        "          # Predict noise for uncond and cond\n",
        "          noise_uncond = self.model(x_uncond, t_tensor, torch.zeros_like(mask))\n",
        "          noise_cond = self.model(x_cond, t_tensor, mask)\n",
        "\n",
        "          # Combine with guidance\n",
        "          noise_pred = noise_uncond + guidance_scale * (noise_cond - noise_uncond)\n",
        "\n",
        "          # DDPM update step (use combined noise_pred)\n",
        "          coef1 = 1 / torch.sqrt(at)\n",
        "          coef2 = (1 - at) / torch.sqrt(1 - a_bar)\n",
        "\n",
        "          x = coef1 * (x - coef2 * noise_pred)\n",
        "\n",
        "          if t > 0:\n",
        "              x += torch.sqrt(bt) * torch.randn_like(x)\n",
        "\n",
        "          # After update, ensure we keep observed values exactly (optional safety)\n",
        "          x = x * (1 - mask) + x_obs * mask\n",
        "\n",
        "          # --- Guidance for Feature 26 ---\n",
        "          # Find samples where Feature 26 was originally missing\n",
        "          missing_for_f26 = (mask[:, feature_26_idx] == 0)\n",
        "          if missing_for_f26.any():\n",
        "              # Get the current imputed values for Feature 26 for these samples\n",
        "              values_to_constrain = x[missing_for_f26, feature_26_idx]\n",
        "\n",
        "              # Calculate absolute differences to each allowed category\n",
        "              diffs = torch.abs(values_to_constrain.unsqueeze(1) - allowed_categories)\n",
        "\n",
        "              # Find the index of the closest allowed category\n",
        "              closest_category_indices = torch.argmin(diffs, dim=1)\n",
        "\n",
        "              # Snap the imputed values to the closest allowed category\n",
        "              x[missing_for_f26, feature_26_idx] = allowed_categories[closest_category_indices]\n",
        "\n",
        "\n",
        "\n",
        "           # --- Guidance for Feature 25 ---\n",
        "          # Find samples where Feature 26 was originally missing\n",
        "          missing_for_f25 = (mask[:, feature_25_idx] == 0)\n",
        "          if missing_for_f25.any():\n",
        "              # Get the current imputed values for Feature 25 for these samples\n",
        "              values_to_constrain = x[missing_for_f25, feature_25_idx]\n",
        "\n",
        "              # Calculate absolute differences to each allowed category\n",
        "              diffs = torch.abs(values_to_constrain.unsqueeze(1) - allowed_categories)\n",
        "\n",
        "              # Find the index of the closest allowed category\n",
        "              closest_category_indices = torch.argmin(diffs, dim=1)\n",
        "\n",
        "              # Snap the imputed values to the closest allowed category\n",
        "              x[missing_for_f25, feature_25_idx] = allowed_categories[closest_category_indices]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # xmin = x.min(dim=0, keepdim=True).values\n",
        "      # xmax = x.max(dim=0, keepdim=True).values\n",
        "\n",
        "      # x_scaled = (x - xmin) / (xmax - xmin + 1e-12)\n",
        "\n",
        "\n",
        "      return x # x_scaled"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Diffusion(input_dim=37, timesteps=18).to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "u8bw1CxnvuMH"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(200):\n",
        "    for batch, mask in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        mask = mask.to(device)\n",
        "\n",
        "        loss = model(batch, mask)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    print(f\"epoch {epoch} | loss {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "T9GDCTjhvzcY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "outputId": "04518b06-8714-429d-f449-125d5294d68e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AcceleratorError",
          "evalue": "CUDA error: out of memory\nSearch for `cudaErrorMemoryAllocation' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAcceleratorError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-652820668.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-234287392.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x0, mask)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;31m# Noise forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# Condition on observed values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-234287392.py\u001b[0m in \u001b[0;36mq_sample\u001b[0;34m(self, x0, t, noise)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnoise\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0ma_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphas_cum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_bar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ma_bar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAcceleratorError\u001b[0m: CUDA error: out of memory\nSearch for `cudaErrorMemoryAllocation' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x_incomplete = X_test_imputed[i]      # has -1 replaced by something\n",
        "# mask = (X_test_missing_mask[i] == 0)  # convert your mask to 1/0 observed/missing\n",
        "\n",
        "# x_incomplete = torch.tensor(x_incomplete).float().to(device)\n",
        "# mask = torch.tensor(mask).float().to(device)\n",
        "\n",
        "# samples = []\n",
        "\n",
        "# for _ in range(20):\n",
        "#     x_gen = model.sample(x_incomplete.unsqueeze(0), mask.unsqueeze(0))\n",
        "#     samples.append(x_gen.cpu().numpy())\n",
        "\n",
        "# samples = np.array(samples)   # (20, 1, 37)"
      ],
      "metadata": {
        "id": "qXLJC4lUv3E8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UcK6bs-zxuxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0835855"
      },
      "outputs": [],
      "source": [
        "def evaluate_imputation(model, data_loader, device):\n",
        "    \"\"\"Evaluate imputation performance.\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    all_imputations = []\n",
        "    all_originals = []\n",
        "    all_masks = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_data_original, batch_mask_original in data_loader:\n",
        "            batch_data_original = batch_data_original.to(device)\n",
        "            batch_mask_original = batch_mask_original.to(device)\n",
        "\n",
        "            # Use the model's sampling method for imputation\n",
        "            imputed_data = model.sample(batch_data_original, batch_mask_original)\n",
        "\n",
        "            all_imputations.append(imputed_data.cpu().numpy())\n",
        "            all_originals.append(batch_data_original.cpu().numpy())\n",
        "            all_masks.append(batch_mask_original.cpu().numpy())\n",
        "\n",
        "    # Concatenate all results\n",
        "    imputations = np.vstack(all_imputations)\n",
        "    originals = np.vstack(all_originals)\n",
        "    masks = np.vstack(all_masks)\n",
        "\n",
        "    return imputations, originals, masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11a04c0c"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL EVALUATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Evaluate on test set\n",
        "print(\"Evaluating model on test set...\")\n",
        "test_imputations, test_originals, test_masks = evaluate_imputation(\n",
        "    model, test_loader, device\n",
        ")\n",
        "\n",
        "print(f\"✓ Test set evaluation completed\")\n",
        "print(f\"  - Test samples: {test_imputations.shape[0]}\")\n",
        "print(f\"  - Features: {test_imputations.shape[1]}\")\n",
        "\n",
        "test_imputations_denorm = test_imputations  # Already in original scale\n",
        "test_original_denorm = X_test_original  # Already in original scale\n",
        "\n",
        "# Calculate comprehensive metrics\n",
        "print(\"\\nCalculating comprehensive metrics...\")\n",
        "feature_metrics = {}\n",
        "\n",
        "# Create masks for missing values (where we need to evaluate imputation)\n",
        "missing_mask = (test_masks == 0)  # True where values were missing (0 in model tensors = missing)\n",
        "\n",
        "for i, feature_name in enumerate(feature_names):\n",
        "    if missing_mask[:, i].sum() > 0:  # Only evaluate features with missing values\n",
        "        # Get imputed and ground truth values for missing positions only\n",
        "        imputed_missing = test_imputations_denorm[missing_mask[:, i], i]\n",
        "        ground_truth_missing = test_original_denorm[missing_mask[:, i], i]\n",
        "\n",
        "        # Calculate metrics\n",
        "        mse = mean_squared_error(ground_truth_missing, imputed_missing)\n",
        "        mae = mean_absolute_error(ground_truth_missing, imputed_missing)\n",
        "\n",
        "        # Correlation\n",
        "        try:\n",
        "            correlation = np.corrcoef(ground_truth_missing, imputed_missing)[0, 1]\n",
        "        except:\n",
        "            correlation = np.nan\n",
        "\n",
        "        # Mean difference and Jensen-Shannon divergence\n",
        "        mean_diff, js_div = calculate_jsd_and_mean_diff(\n",
        "            imputed_missing, ground_truth_missing, feature_name\n",
        "        )\n",
        "\n",
        "        feature_metrics[feature_name] = {\n",
        "            'n_missing': missing_mask[:, i].sum(),\n",
        "            'mse': mse,\n",
        "            'mae': mae,\n",
        "            'correlation': correlation,\n",
        "            'mean_difference': mean_diff,\n",
        "            'js_divergence': js_div,\n",
        "        }\n",
        "\n",
        "print(f\"✓ Metrics calculated for {len(feature_metrics)} features with missing values\")\n",
        "\n",
        "# Display metrics for last 4 features (as requested)\n",
        "print(f\"\\n\" + \"=\"*100)\n",
        "print(\"METRICS FOR LAST 4 FEATURES\")\n",
        "print(\"=\"*100)\n",
        "print(f\"{'Feature':<15} {'N_Miss':<8} {'MSE':<10} {'MAE':<10} {'Corr':<8} {'Mean_Diff':<10} {'JS_Div':<8}\")\n",
        "print(\"-\" * 100)\n",
        "\n",
        "last_4_features = list(feature_metrics.keys())[-4:] if len(feature_metrics) >= 4 else list(feature_metrics.keys())\n",
        "\n",
        "for feature in last_4_features:\n",
        "    metrics = feature_metrics[feature]\n",
        "    print(f\"{feature:<15} {metrics['n_missing']:<8} {metrics['mse']:<10.4f} {metrics['mae']:<10.4f} \"\n",
        "          f\"{metrics['correlation']:<8.3f} {metrics['mean_difference']:<10.4f} {metrics['js_divergence']:<8.4f} \")\n",
        "\n",
        "# Summary statistics\n",
        "all_mse = [m['mse'] for m in feature_metrics.values() if not np.isnan(m['mse'])]\n",
        "all_mae = [m['mae'] for m in feature_metrics.values() if not np.isnan(m['mae'])]\n",
        "all_corr = [m['correlation'] for m in feature_metrics.values() if not np.isnan(m['correlation'])]\n",
        "all_mean_diff = [m['mean_difference'] for m in feature_metrics.values() if not np.isnan(m['mean_difference'])]\n",
        "all_js_div = [m['js_divergence'] for m in feature_metrics.values() if not np.isnan(m['js_divergence'])]\n",
        "\n",
        "print(f\"\\nSummary Statistics Across All Features:\")\n",
        "print(f\"  - Average MSE: {np.mean(all_mse):.4f} ± {np.std(all_mse):.4f}\")\n",
        "print(f\"  - Average MAE: {np.mean(all_mae):.4f} ± {np.std(all_mae):.4f}\")\n",
        "print(f\"  - Average Correlation: {np.mean(all_corr):.3f} ± {np.std(all_corr):.3f}\")\n",
        "print(f\"  - Average Mean Difference: {np.mean(all_mean_diff):.4f} ± {np.std(all_mean_diff):.4f}\")\n",
        "print(f\"  - Average JS Divergence: {np.mean(all_js_div):.4f} ± {np.std(all_js_div):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a047bb73"
      },
      "outputs": [],
      "source": [
        "# Create the visualization\n",
        "plot_prediction_scatter(test_imputations_denorm, test_original_denorm, test_masks, feature_names, n_features=37)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HJRHURYuzz1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDgv-wkViD-u"
      },
      "outputs": [],
      "source": [
        "# Distribution comparison plots\n",
        "plot_distribution_comparison(test_imputations_denorm, test_original_denorm,\n",
        "                             test_masks, feature_names, n_features=25)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BU2C4oMd0CHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lI7StssOGmfp"
      },
      "outputs": [],
      "source": [
        "def generate_samples(model, X_test, test_loader, device, n_samples_per_test=100):\n",
        "    \"\"\"Generate multiple samples for a dataset using the trained model.\n",
        "    \"\"\"\n",
        "    # We'll generate multiple samples\n",
        "    test_samples = np.zeros((X_test.shape[0], n_samples_per_test, X_test.shape[1]))\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Create a progress bar for all samples\n",
        "        from tqdm import tqdm\n",
        "\n",
        "        for batch_idx, (batch_data, batch_mask) in enumerate(tqdm(test_loader, desc=\"Generating Samples\")):\n",
        "            batch_data = batch_data.to(device)\n",
        "            batch_mask = batch_mask.to(device)\n",
        "\n",
        "            # Calculate the indices for this batch\n",
        "            start_idx = batch_idx * test_loader.batch_size\n",
        "            end_idx = min(start_idx + test_loader.batch_size, X_test.shape[0])\n",
        "            actual_batch_size = end_idx - start_idx\n",
        "\n",
        "            # Generate multiple samples for each item in the batch\n",
        "            for j in range(n_samples_per_test):\n",
        "                # Get imputed sample using the model's sampling method\n",
        "                imputed = model.sample(batch_data, batch_mask)\n",
        "\n",
        "                # Store the samples (already in original scale since we didn't normalize)\n",
        "                test_samples[start_idx:end_idx, j, :] = imputed.cpu().numpy()\n",
        "    print(f\"✓ Generated samples shape: {test_samples.shape}\")\n",
        "    print(f\"  - {test_samples.shape[0]} samples\")\n",
        "    print(f\"  - {test_samples.shape[1]} generated variations per sample\")\n",
        "    print(f\"  - {test_samples.shape[2]} features per sample\")\n",
        "\n",
        "    # Data is already in original scale (no denormalization needed)\n",
        "    test_samples_final = test_samples.copy()\n",
        "\n",
        "    # Calculate summary statistics\n",
        "    mean_across_samples = test_samples_final.mean(axis=1)  # Mean across the 100 samples\n",
        "\n",
        "    print(f\"  - Range of means: [{mean_across_samples.min():.4f}, {mean_across_samples.max():.4f}]\")\n",
        "\n",
        "    return test_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sjkbko3oFJQV"
      },
      "outputs": [],
      "source": [
        "# Test Evaluation\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"TEST EVALUATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Generate multiple samples for test using the trained model\n",
        "print(f\"Generating 100 samples for each of {X_test.shape[0]} test samples...\")\n",
        "\n",
        "test_samples = generate_samples(\n",
        "    model, X_test, test_loader, device, n_samples_per_test=100\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFWebQ2AzSsJ"
      },
      "outputs": [],
      "source": [
        "from evaluate import *\n",
        "test_score = compute_score(generated_samples=test_samples, set_name='test')\n",
        "print(\"Test score:\", test_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4d6a8623"
      },
      "outputs": [],
      "source": [
        "# Test2 Evaluation\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"TEST2 EVALUATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Generate multiple samples for test2 using the trained model\n",
        "print(f\"Generating 100 samples for each of {X_test2.shape[0]} test2 samples...\")\n",
        "\n",
        "test2_samples = generate_samples(\n",
        "    model, X_test2, test2_loader, device, n_samples_per_test=100\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fc755a46"
      },
      "outputs": [],
      "source": [
        "rng = np.random.default_rng()\n",
        "id = rng.integers(1e8, 1e9-1)\n",
        "np.save(f\"{id}.npy\", test2_samples)"
      ]
    }
  ]
}